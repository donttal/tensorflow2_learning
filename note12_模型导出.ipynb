{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorFlow 模型导出 \n",
    "使用 SavedModel 完整导出模型 \n",
    "在部署模型时，我们的第一步往往是将训练好的整个模型完整导出为一系列标准格式的文件，然后即可在不同的平台上部署模型文件。这时，TensorFlow 为我们提供了 SavedModel 这一格式。与前面介绍的 Checkpoint 不同，SavedModel 包含了一个 TensorFlow 程序的完整信息： 不仅包含参数的权值，还包含计算的流程（即计算图） 。当模型导出为 SavedModel 文件时，无需建立模型的源代码即可再次运行模型，这使得 SavedModel 尤其适用于模型的分享和部署。后文的 TensorFlow Serving（服务器端部署模型）、TensorFlow Lite（移动端部署模型）以及 TensorFlow.js 都会用到这一格式。\n",
    "\n",
    "Keras 模型均可方便地导出为 SavedModel 格式。不过需要注意的是，因为 SavedModel 基于计算图，所以对于使用继承 tf.keras.Model 类建立的 Keras 模型，其需要导出到 SavedModel 格式的方法（比如 call ）都需要使用 @tf.function 修饰（ @tf.function 的使用方式见 前文 ）。然后，假设我们有一个名为 model 的 Keras 模型，使用下面的代码即可将模型导出为 SavedModel：\n",
    "\n",
    "tf.saved_model.save(model, \"保存的目标文件夹名称\")\n",
    "在需要载入 SavedModel 文件时，使用\n",
    "\n",
    "model = tf.saved_model.load(\"保存的目标文件夹名称\")\n",
    "即可。\n",
    "\n",
    "提示\n",
    "\n",
    "对于使用继承 tf.keras.Model 类建立的 Keras 模型 model ，使用 SavedModel 载入后将无法使用 model() 直接进行推断，而需要使用 model.call() 。\n",
    "\n",
    "以下是一个简单的示例，将 前文 MNIST 手写体识别的模型 进行导出和导入。\n",
    "\n",
    "导出模型到 saved/1 文件夹："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as t\n",
    "\n",
    "# 数据获取及预处理\n",
    "import numpy as np\n",
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "        # MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        # 从数据集中随机取出batch_size个元素并返回\n",
    "        index = np.random.randint(0, np.shape(self.train_data)[0], batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = MNISTLoader()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples\n60000/60000 [==============================] - 3s 43us/sample - loss: 0.2982 - sparse_categorical_accuracy: 0.9162\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1553b0ba8>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_loader.train_data, data_loader.train_label, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /Users/lhj/anaconda3/envs/tf2Learn/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: saved/1/assets\n"
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"saved/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "将 saved/1 中的模型导入并测试性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "test accuracy: 0.951100\n"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "model = tf.saved_model.load(\"saved/1\")\n",
    "data_loader = MNISTLoader()\n",
    "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = model(data_loader.test_data[start_index: end_index])\n",
    "    sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n",
    "print(\"test accuracy: %f\" % sparse_categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "使用继承 tf.keras.Model 类建立的 Keras 模型同样可以以相同方法导出，唯须注意 call 方法需要以 @tf.function 修饰，以转化为 SavedModel 支持的计算图，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):         # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs)    # [batch_size, 784]\n",
    "        x = self.dense1(x)          # [batch_size, 100]\n",
    "        x = self.dense2(x)          # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "data_loader = MNISTLoader()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples\n60000/60000 [==============================] - 3s 45us/sample - loss: 0.2959 - sparse_categorical_accuracy: 0.9168\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x149cafa20>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_loader.train_data, data_loader.train_label, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Assets written to: saved/2/assets\n"
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"saved/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "test accuracy: 0.954600\n"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "model = tf.saved_model.load(\"saved/2\")\n",
    "data_loader = MNISTLoader()\n",
    "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    # 唯一不同的是需要显式调用call函数\n",
    "    y_pred = model.call(data_loader.test_data[start_index: end_index])\n",
    "    sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n",
    "print(\"test accuracy: %f\" % sparse_categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keras Sequential save 方法（Jinpeng）\n",
    "我们以 keras 模型训练和保存为例进行讲解，如下是 keras 官方的 mnist 模型训练样例。\n",
    "\n",
    "源码地址:\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "以上代码，是基于 keras 的 Sequential 构建了多层的卷积神经网络，并进行训练。\n",
    "\n",
    "为了方便起见可使用如下命令拷贝到本地:\n",
    "\n",
    "curl -LO https://raw.githubusercontent.com/keras-team/keras/master/examples/mnist_cnn.py\n",
    "然后，在最后加上如下一行代码（主要是对 keras 训练完毕的模型进行保存）:\n",
    "\n",
    "model.save('mnist_cnn.h5')\n",
    "在终端中执行 mnist_cnn.py 文件，如下:\n",
    "\n",
    "python mnist_cnn.py\n",
    "警告\n",
    "\n",
    "该过程需要连接网络获取 mnist.npz 文件（https://s3.amazonaws.com/img-datasets/mnist.npz），会被保存到 $HOME/.keras/datasets/ 。如果网络连接存在问题，可以通过其他方式获取 mnist.npz 后，直接保存到该目录即可。\n",
    "\n",
    "执行过程会比较久，执行结束后，会在当前目录产生 mnist_cnn.h5 文件（HDF5 格式），就是 keras 训练后的模型，其中已经包含了训练后的模型结构和权重等信息。\n",
    "\n",
    "在服务器端，可以直接通过 keras.models.load_model(\"mnist_cnn.h5\") 加载，然后进行推理；在移动设备需要将 HDF5 模型文件转换为 TensorFlow Lite 的格式，然后通过相应平台的 Interpreter 加载，然后进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}